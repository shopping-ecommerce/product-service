server:
  port: 8083
  servlet:
    context-path: /product

spring:
  application:
    name: product-service

  # üëâ ∆Øu ti√™n l·∫•y t·ª´ ENV SPRING_DATA_MONGODB_URI; n·∫øu kh√¥ng c√≥ th√¨ d√πng service-name "mongodb"
  data:
    mongodb:
      uri: ${SPRING_DATA_MONGODB_URI:mongodb://root:root@mongodb:27017/product_db?authSource=admin}

  # Upload multipart (cho /update k√®m ·∫£nh)
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB
  kafka:
    bootstrap-servers: ${DBKK_CONNECTION:kafka}:9094
    consumer:
      group-id: product-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "*"
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
  cloud:
    openfeign:
      client:
        config:
          # Timeout m·∫∑c ƒë·ªãnh cho t·∫•t c·∫£ Feign client
          default:
            connect-timeout: 60000
            read-timeout: 120000
          # File-service (ƒë·ªçc t·ª´ ENV FEIGN_FILE, fallback sang service-name trong network)
          file-service:
            url: ${FEIGN_FILE:http://file-service:8084/file}
            connect-timeout: 30000
            read-timeout: 60000
          user-service:
            url: ${FEIGN_USER:http://user-service:8082/info}
            connect-timeout: 30000
            read-timeout: 60000
          gemini-service:
            url: ${FEIGN_GEMINI:http://gemini-service:5001/gemini}
            connect-timeout: 30000
            read-timeout: 60000
          review-service:
            url: ${FEIGN_REVIEW:http://review-service:8088/feedback}
            connect-timeout: 30000
            read-timeout: 60000

  elasticsearch:
    uris: ${ELASTICSEARCH_URI:http://elasticsearch:9200}
    connection-timeout: 5s
    socket-timeout: 10s
    max-retry-attempts: 3
product:
  cleanup:
    enabled: true
    days-before-deletion: 30
    cron: "0 0 2 * * SUN"  # 2h s√°ng h√†ng ng√†y (6-field cho Spring)
    batch-size: 100
    delete-images: true

# Custom elasticsearch configuration
elasticsearch:
  host: ${ELASTICSEARCH_HOST:elasticsearch}
  port: 9200
service:
  tokens:
    file-service: ${FILE_SERVICE_TOKEN:}
logging:
  level:
    iuh.fit.se.batch: INFO